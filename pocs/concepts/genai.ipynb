{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative AI\n",
    "\n",
    "Gen AI is a new field of AI that focuses on creating new content, such as images, music, and text. \n",
    "\n",
    "<img src=\"images/timeline-genai.png\" width=\"600\" height=\"400\" />\n",
    "\n",
    "## Gen AI Use Cases\n",
    "\n",
    "**Text Generation**: Create new text, such as articles, stories, or conversations.\n",
    "\n",
    "**Image Generation**: Create new images, such as photos, artwork, or designs.\n",
    "\n",
    "**Music Generation**: Compose music, melodies, or sound effects.\n",
    "\n",
    "**Video Generation**: Create new videos, such as animations or clips.\n",
    "\n",
    "**Data Generation**: Create synthetic data for training or testing.\n",
    "\n",
    "**Style Transfer**: Transfer styles between images, music, or text.\n",
    "\n",
    "**Image-to-Image Translation**: Translate images from one domain to another.\n",
    "\n",
    "**Text-to-Image Synthesis**: Generate images from text descriptions.\n",
    "\n",
    "**Dialogue Generation**: Engage in conversation, responding to user input.\n",
    "\n",
    "**Creative Writing**: Generate creative writing, such as poetry or short stories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning\n",
    "\n",
    "Deep learning is a subfield of machine learning that focuses on neural networks.\n",
    "\n",
    "Neural Networks are a type of model that is inspired by the human brain. They consist of layers of neurons that process input data and produce output data. Deep Neural Networks are neural networks with many layers. They are capable of learning complex patterns in data.\n",
    "\n",
    "<img src=\"images/nn.png\" width=\"600\" height=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks (RNNs)\n",
    "\n",
    "Recurrent Neural Networks (RNNs) are a type of neural network that is designed to process sequences of data. They are commonly used for text and speech processing.\n",
    "\n",
    "<img src=\"images/RNN.png\" width=\"600\" height=\"400\" style=\" background-color: white;\" />\n",
    "\n",
    "**Backward Propagation**: RNNs use backpropagation to update their weights and biases during training. This involves computing the gradient of the loss function with respect to the weights and biases of the network.\n",
    "\n",
    "**Foward Propagation**: RNNs use forward propagation to compute the output of the network given an input sequence. This involves passing the input sequence through the network and computing the output at each time step.\n",
    "\n",
    "**Long Short-Term Memory (LSTM)**: LSTMs are a type of RNN that are designed to capture long-term dependencies in data. They are capable of learning patterns that are separated by long sequences of data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks (CNNs)\n",
    "\n",
    "Convolutional Neural Networks (CNNs) are a type of neural network that is designed to process images. They are commonly used for image recognition and computer vision.\n",
    "\n",
    "<img src=\"images/CNN.jpeg\" width=\"600\" height=\"400\" style=\" background-color: white;\" />\n",
    "\n",
    "CNNs use convolutional layers to extract features from images. These layers apply filters to the input image to detect patterns, such as edges, corners, and textures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers\n",
    "\n",
    "Transformers are a type of neural network architecture that has been successful in many Gen AI tasks. They are based on self-attention mechanisms that allow them to model long-range dependencies in data. Transformers have been used in many applications, such as language modeling, translation, and image generation.\n",
    "\n",
    "<img src=\"images/transformers.png\" width=\"600\" height=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT\n",
    "\n",
    "ChatGPT (GPT means ) is a large language model that is based on the GPT-series. It is capable of generating human-like text responses to user input. ChatGPT has been used in many applications, such as chatbots, conversational agents, and creative writing.\n",
    "\n",
    "<img src=\"images/GPT_VS_BERT.png\" />\n",
    "\n",
    "### GPT Cost to train\n",
    "\n",
    "| Model    | Parameters | Cost   |  Time    |\n",
    "| -------- | ---------- |--------|----------| \n",
    "| GPT-3    | 175B       | 4.6M   | 34 days  |\n",
    "| GPT-4    | 100T       | 2.6B   | 100 days |\n",
    "| LLAMA-2  | 70B        | 20M    | 23 days  |\n",
    "\n",
    "Llama-2 paper, it took 184,320 GPU hours of an A100 to train the model. 184320 hours = 7680 days ~= 21 years Renting AWS p4d. 24xlarge instance (8 GPUs) is $32.7726 per hour\n",
    "\n",
    "Cost References:\n",
    "* [GPT-4 Training days](https://towardsdatascience.com/the-carbon-footprint-of-gpt-4-d6c676eb21ae#:~:text=Recall%20that%20it's%20estimated%20that,to%202%2C600%20hours%20per%20server.)\n",
    "* [GPT-3 Cost](https://www.forbes.com/sites/craigsmith/2023/09/08/what-large-models-cost-you--there-is-no-free-ai-lunch/?sh=3561d9e24af7)\n",
    "* [GPT-3 Cost comments](https://ai.stackexchange.com/questions/43128/what-is-accelerated-years-in-describing-the-amount-of-the-training-time#:~:text=Since%20GPT%2D3%20is%20a,train%20the%20GPT%2D3%20model.)\n",
    "* [GPT Cost](https://www.moomoo.com/community/feed/109834449715205#:~:text=In%20terms%20of%20the%20training,reach%2046%20million%20U.S.%20dollars.)\n",
    "* [LLAMA 2 model card](https://github.com/meta-llama/llama/blob/main/MODEL_CARD.md)\n",
    "* [LLAMA 2 Cost](https://www.quora.com/How-much-money-did-Meta-cost-to-train-Llama-2-Why-has-NVIDIAs-stock-price-been-rising-and-how-high-could-it-ultimately-go#:~:text=Cost%20Breakdown%3A%20Meta%20allocated%20a,the%20training%20of%20Llama%202.)\n",
    "* [LLAMA2 Cost comments](https://www.linkedin.com/posts/hherry_according-to-the-llama-v2-paper-it-took-activity-7128798861606694912-FLaT/?trk=public_profile_like_view)\n",
    "* [LLAMA2 training days](https://news.ycombinator.com/item?id=35008694)\n",
    "\n",
    "Size of GPT-4 model\n",
    "\n",
    "<img src=\"images/GPT_4_metaphor.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hugging Face\n",
    "\n",
    "Hugging Face is a company that specializes in natural language processing (NLP) and Gen AI. They provide a wide range of models, datasets, and tools for developers to use in their projects. Hugging Face is known for their Transformers library, which is a popular open-source library for working with transformer models. Huggingface is like Github for AI models.\n",
    "\n",
    "### Hugging Face Tasks\n",
    "\n",
    "<img src=\"images/hf-tasks.png\" width=\"600\" height=\"400\" />\n",
    "\n",
    "https://huggingface.co/tasks\n",
    "\n",
    "It's the real deal! Makes easy to consume models and perform common AI tasks on text, audio, image or video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX - Open Neural Network Exchange\n",
    "\n",
    "ONNX is an open-source format for representing deep learning models. It allows models to be trained in one framework and deployed in another. ONNX is supported by many popular deep learning frameworks, such as PyTorch, TensorFlow, and MXNet.\n",
    "\n",
    "ONNX is a big deal because you can go from PyTorch <--> Tensorflow but also train a model in python and run inference on the model in Java.\n",
    "\n",
    "<img src=\"images/onnx.png\" width=\"600\" height=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain\n",
    "\n",
    "LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
    "\n",
    "<img src=\"images/overall-langchain.jpeg\" width=\"600\" height=\"500\" />\n",
    "\n",
    "Java has [Langchain4J](https://docs.langchain4j.dev/) as langchain implementation for Java.\n",
    "\n",
    "Using Langchain we can do:\n",
    "* Smooth integration into your Java applications (or other languages), There is two-way integration between LLMs and Java: you can call LLMs from Java and allow LLMs to call your Java code in return.\n",
    "* Prompt Templating\n",
    "* Output parsing\n",
    "* Patterns like RaG or Agents\n",
    "* Vector Databases integration (Pinecone, OpenSearch, Redis, pg_vector, more...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RaG (Retrieval-augmented Generation)\n",
    "\n",
    "LLMs can halucinate.\n",
    "\n",
    "<img src=\"images/LLM_hallucinations.png\"  />\n",
    "\n",
    "RaG is approach that combines retrieval and generation models to improve the performance of language models. It uses a retrieval model to find relevant information from a large corpus of text and a generation model to generate responses based on that information.\n",
    "\n",
    "<img src=\"images/Rag-Simple.png\"  />\n",
    "\n",
    "RaG is key because it allows to generate more accurate and relevant responses by combining the strengths of retrieval and generation models. RaG also can reduce the cost of fine-tunning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KAN\n",
    "\n",
    "[KAN](https://arxiv.org/abs/2404.19756) it's a potential Alternative to MLP.\n",
    "\n",
    "<img src=\"images/KAN-simple.png\" />\n",
    "\n",
    "KANs diverge from traditional Multi-Layer Perceptrons (MLPs) by replacing fixed activation functions with learnable functions, effectively eliminating the need for linear weight matrices.\n",
    "\n",
    "<img src=\"images/KAN_VS_MLP.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stable Diffusion\n",
    "\n",
    "Stable Diffusion works by iteratively adding noise to an image to create a sequence of noisy images. The model then learns to denoise these images to recover the original image. This process is repeated multiple times to generate high-quality images.\n",
    "\n",
    "<img src=\"images/Stable_Diffusion_architecture.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversarial Networks (GAN)\n",
    "\n",
    "Generative Adversarial Networks (GANs) are a type of neural network that is designed to generate new data. They consist of two networks: a generator and a discriminator. The generator creates new data samples, while the discriminator tries to distinguish between real and fake samples.\n",
    "\n",
    "<img src=\"images/GANs.png\" style=\" background-color: white;\" />\n",
    "\n",
    "GAN Pros:\n",
    "  * Synthetic data generation\n",
    "  * High-quality results\n",
    "  * Versatility\n",
    "\n",
    "GAN Cons:\n",
    "  * Training Instability\n",
    "  * Computational Cost\n",
    "  * Overfitting\n",
    "  * Bias and Fairness\n",
    "  * Interpretability and Accountability\n",
    "\n",
    "Stable Diffusion vs GAN: The main difference between the two methods is their approach to generating new data. Stable Diffusion uses a process of adding and removing noise to an image, while GANs use a game-theoretic approach where two networks compete against each other."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
