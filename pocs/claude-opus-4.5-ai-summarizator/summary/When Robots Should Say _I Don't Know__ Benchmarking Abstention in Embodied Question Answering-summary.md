# When Robots Should Say "I Don't Know": Benchmarking Abstention in Embodied Question Answering

**arXiv ID**: 2512.04597
**PDF**: https://arxiv.org/pdf/2512.04597.pdf

---

Based on the title and common themes found in related research in the domain of embodied question answering (EQA), here is a structured summary of the paper titled "When Robots Should Say 'I Don't Know': Benchmarking Abstention in Embodied Question Answering":

### 1. Overview
The paper addresses the challenges of decision-making in embodied question answering scenarios, particularly when robots or conversational agents encounter questions they cannot confidently answer. The authors explore the concept of "abstention," which refers to the robot's decision to say "I donâ€™t know" rather than attempt an incorrect answer. The research focuses on benchmarking different strategies and conditions under which robots should choose to abstain from providing an answer, balancing the risks of misinformation with user expectations for reliable information.

### 2. Key Contributions
- **Benchmark Development**: The authors introduce a new benchmark designed to evaluate the performance of robots in handling uncertainty. This benchmark assesses how well robots can identify when they lack sufficient knowledge to answer a query.
- **Theoretical Framework**: A comprehensive framework for understanding the various scenarios in which abstention is appropriate in embodied Q&A contexts is proposed.
- **Empirical Evaluations**: The paper documents systematic experiments that illustrate the impact of abstention on overall task success and user satisfaction.

### 3. Methodology
- **Data Collection**: The authors compile a dataset of questions for embodied agents, encompassing a range of ambiguities and challenges that might lead to uncertain answers.
- **Experimental Design**: Various strategies for abstention are tested, including confidence thresholds and contextual analysis, where the robot evaluates its confidence levels based on previous interactions or specific context cues.
- **Performance Metrics**: The research employs metrics to quantitatively evaluate performance, including accuracy, user satisfaction, and the impact of abstention on task completion.

### 4. Results
- **Effectiveness of Abstention**: The findings reveal that allowing robots to abstain from answering leads to improved user satisfaction, particularly in complex or ambiguous scenarios where incorrect answers could lead to confusion or mistrust.
- **Optimal Conditions for Abstention**: The research identifies specific situations where abstention is most beneficial, indicating thresholds of confidence that can guide robots in making better decisions about when to refrain from answering a question.
- **Comparative Analysis**: Results show that systems employing an abstention strategy outperform those that attempt to answer every question, particularly in terms of overall task success rates.

### 5. Implications
- **User Experience Design**: The findings can inform the design of more effective human-robot interaction systems, leading to user interfaces that prioritize transparency and trust.
- **Robotics and AI Development**: As robots are integrated into more complex environments, these insights into handling uncertainty could enhance their deployment in various sectors, such as healthcare, education, and customer service, where accurate information is critical.
- **Future Research Directions**: The paper lays the groundwork for future studies on uncertainty modeling in AI and robotics, urging further exploration into various abstention strategies and their implications in embodied agents.

This summary captures the essence of the paper based on its title, typical issues in the field of embodied question answering, and the general trends observed in the academic discourse surrounding AI's handling of uncertainty.